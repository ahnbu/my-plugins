# 프로젝트 문서 관리 & PM 방법론 조사 보고서

> 날짜: 2026-02-25
> 대상: 1인 개발자 (Obsidian + Claude Code + Git 환경)
> 배경: AI 에이전트 기반 개발 문서화 사례 5건 분석을 토대로, 비개발/개발 영역 전체를 아우르는 문서 관리 방법론 조사

---

## Executive Summary

AI 에이전트 시대의 문서 관리는 **"문서의 소비자가 사람에서 사람+기계로 확장"**된다는 하나의 변화로 요약된다. 이 조사는 전통 PM 방법론(PMBOK, PRINCE2, Agile), 지식 관리(PARA, Zettelkasten), 개발 문서화(ADR, Docs-as-Code), AI 에이전트 시대의 새로운 패턴을 조사하고, 기존에 분석한 5개 사례(bkit, team-attention, 조아영, 마누스, 류장근)와 교차 검증했다.

**핵심 발견:**

1. 전통 PM 문서의 과잉은 AI 시대에 **자동 소비 구조**로 해결 가능 → 가설 1 확인
2. 사람용/기계용 문서는 **형식 분리보다 "하나의 소스, 두 소비자" 전략**이 현실적 → 가설 2 수정
3. 비개발 영역의 가장 큰 공백은 **의사결정 기록의 부재** → 가설 3 확인
4. Context Engineering은 PARA/Zettelkasten의 재발견이 아니라 **보완적 관계** → 가설 4 수정

**즉시 도입 권고 3가지**: Decision Record 도입, YAML frontmatter 일관 적용, `/wrap` 검증 단계 추가

---

## Part 1. 비개발 영역 문서 관리

### 1-1. 전통 PM 문서 체계

| 기준 | PMBOK 7 | PRINCE2 | Agile |
|------|---------|---------|-------|
| 문서 철학 | 원칙 기반, 유연 | 프로세스 기반, 엄격 | 최소 충분(JBGE) |
| 문서 양 | 중간 | 많음 (26개 정의) | 적음 |
| 구조화 정도 | 중간 | 높음 | 낮음 |
| 적합 규모 | 범용 | 대규모/거버넌스 | 소규모/빠른 변화 |

**PMBOK 7판의 전환**: 6판의 49개 프로세스 → 7판의 12개 원칙 + 8개 성과 영역. "무엇을 달성해야 하는가"에 초점. 이 변화는 AI 시대의 유연한 문서 관리와 방향이 일치한다.

**Agile의 JBGE 원칙**: "이 문서가 없으면 누군가 일을 못 하는가?" — 이 질문을 AI 에이전트 시대에 확장하면 "이 문서가 없으면 미래의 나 또는 Claude가 맥락을 잃는가?"가 된다.

**시사점**: Agile JBGE가 1인 환경에 가장 적합. PRINCE2에서는 "Management Products" 개념(문서를 산출물로 명시적 정의)만 차용.

### 1-2. 지식 관리 방법론

| 방법론 | 핵심 원리 | 강점 | 한계 |
|--------|-----------|------|------|
| **PARA** | 실행 가능성(actionability) 기준 분류 | 단순, 어떤 도구에서든 적용 | 노트 간 연결 없음 |
| **Zettelkasten** | 원자적 메모 + 링크 기반 연결 | 지식 창발에 탁월 | 학습 곡선, 프로젝트 관리 부재 |
| **PKM 2025+** | AI 통합, 시맨틱 검색, RAG | 자동화된 지식 합성 | 도구 의존성 |

**최적 조합**: PARA의 폴더 구조(Projects/Areas/Resources/Archives)로 실행 지향 정리 + Zettelkasten의 `[[위키링크]]`로 지식 연결 = **하이브리드 방식**. Obsidian이 이 조합의 최적 구현체.

**PKM 트렌드**: "Agentic Knowledge Management" — AI가 지식 베이스를 관찰하며 선제적으로 제안하는 방향. obsidian-claude-pkm 같은 스타터킷이 등장.

### 1-3. 의사결정 기록 체계

**비개발 영역의 가장 큰 공백**: 개발에서는 ADR(Architecture Decision Record)이 정착되었으나, 비개발 영역에서는 의사결정 기록이 체계적으로 이루어지지 않음.

**Decision Record의 핵심 필드**: Context(왜 결정이 필요했나) → Decision(무엇을 선택했나) → Consequences(결과와 트레이드오프)

**확장 사례**: 일부 팀은 디렉토리명을 `decisions/`로 바꾸고 벤더 선택, 일정 변경, 전략 결정 등 모든 종류의 의사결정에 MADR 템플릿을 동일 적용.

**Decision Journal (Farnam Street)**: 개인용 의사결정 일지. 결정 직후(결과 알기 전) 기록 → 분기 리뷰 → 의사결정 편향 발견. "결과가 좋았는가"가 아니라 "프로세스가 건전했는가"를 평가.

**시사점**: MADR 형식을 Obsidian `decisions/` 폴더에 적용. 기술/비기술 구분 없이 동일 템플릿. CHANGELOG("무엇이 바뀌었나")와 ADR("왜 그렇게 결정했나")은 보완적 관계.

### 1-4. 회의록과 액션 아이템 추적

**핵심 원칙**: 논의 내용(Notes)과 액션 아이템(Action Items)을 명확히 분리. 액션 아이템의 3요소 = 담당자(Who) + 구체적 행동(What) + 기한(When).

**AI 자동화 도구**: Otter.ai, Fireflies.ai, Fathom — 자동 전사 → AI 요약 → 액션 아이템 추출 → PM 도구 연동.

**시사점**: 1인 환경에서는 정식 회의록보다 의사결정 기록 + 액션 아이템 추출이 핵심. Obsidian Daily Note에 `#action` 태그로 기록, Dataview로 미완료 항목 자동 집계.

### 1-5. 비개발 실무 사례

| 도구 | 데이터 소유권 | AI 연동 | 최적 대상 |
|------|-------------|---------|-----------|
| **Obsidian** | 로컬 MD (완전 소유) | Claude Code 직접 R/W | 1인/개인 PKM |
| **Notion** | 클라우드 | API 연동 필요 | 소규모 팀 |
| **Confluence** | 클라우드 | Atlassian 생태계 | 엔터프라이즈 |

**실사례**: Sebastien Dubois(솔로 파운더) — Obsidian을 SSOT로, PARA + Zettelkasten 하이브리드 구조. Daily Note를 허브로 활용.

---

## Part 2. 개발 영역 문서 관리

### 2-1. Architecture Decision Record (ADR)

**진화 경로**: Nygard 원본(5섹션, 2011) → Y-Statements(한 문장) → MADR 4.0(섹션 기반 Markdown, 2024)

**성공 패턴**: `/docs/adr/` 폴더에 코드와 함께 버전 관리 + PR 리뷰에 포함 + "돌이키기 어려운 결정"에만 작성

**실패 패턴**: 별도 Wiki에 저장 → 방치, 너무 상세하게 → solution design과 혼동, 승인 과중 → 작성 회피

**도구**: 1인 개발자에게 adr-tools/Log4brains는 과함. `docs/decisions/`에 MADR minimal 템플릿 Markdown 파일로 충분.

### 2-2. Docs-as-Code 파이프라인

**개념**: 문서를 코드와 동일한 도구(Markdown + Git + CI/CD + SSG)로 관리.

**성공 사례**:
- Pinterest PDocs: 140+ 문서 프로젝트, 80+ 팀 채택. AI 챗봇 통합
- Squarespace: Backstage + TechDocs + Mermaid 다이어그램 버전 관리

**실패 공통 패턴**: 도구만 도입하고 문화 전환 없음, 문서를 코드와 별도 리포에 분리, 자동 검증 없음

**현재 환경**: 이미 Docs-as-Code 실천 중(CLAUDE.md + CHANGELOG.md + handoff/ 이 Git 리포에 동거). 부족한 것은 자동 검증(lint, link check).

### 2-3. API 문서화와 SSOT

**SSOT 원칙**: 하나의 원본에서 다른 모든 형식이 파생. 수동 동기화 제거 → 불일치 방지.

**현재 환경 적용**: plugin.json ↔ marketplace.json 일치 검증(pre-commit hook)이 이미 SSOT 실천. REST API가 없으므로 별도 도구(Scalar, Redoc) 불필요.

### 2-4. Engineering Wiki와 Runbook

**"문서 무덤" 5대 원인** (Stack Overflow 설문):
1. Wiki가 개발 도구 밖에 존재 (컨텍스트 스위칭 비용)
2. "무엇"은 저장되지만 "왜"는 사라짐
3. 한 번 오래된 문서 → 전체 위키 불신
4. 78% 개발자가 "오래된 정보"를 불신 1순위로 지목
5. 65% 개발자가 정보 검색에 읽기보다 더 많은 시간 소비

**해결책**: 문서를 코드 옆에 배치(Git 리포) + AI 기반 문서 신선도 감지 + 코드 변경 시 관련 문서 자동 플래그

**Runbook**: 하나의 런북 = 하나의 목적. 포스트모템 후 자동 업데이트. 플러그인 운영에 적용 가능("hook 실패 시", "plugin update 후 커맨드 미출현 시" 등).

### 2-5. AI 보조 개발 환경의 문서화

**새로운 문서 유형**: CLAUDE.md, .cursorrules, AGENTS.md, .github/copilot-instructions.md — "기계가 읽는 문서"

**5개 사례에서 일반화한 6대 패턴**:

| 패턴 | 대표 사례 | 일반 원칙 |
|------|-----------|-----------|
| 기계용/사람용 분리 | bkit (.pdca-status.json vs 보고서 md) | JSON은 AI용, Markdown은 사람용 |
| 세션 간 연속성 | 조아영 (/wrap→/morning), team-attention | AI 세션은 stateless → 명시적 핸드오프 필수 |
| 결정 전 재참조 강제 | 마누스 ("plan 파일을 다시 읽어라") | CLAUDE.md 규칙으로 "X 전에 Y를 읽어라" |
| 자동 문서 업데이트 | team-attention (doc-updater) | 세션 종료 시 자동 갱신 = 문서 부패 방지 |
| 피드백 루프 | 조아영 (RLHF식), bkit (Match Rate) | 효과 측정 → 점진 개선 |
| 극단적 단순성도 유효 | 마누스 (규칙 1개, 파일 3개) | 핵심 문제만 해결하면 복잡한 시스템 불필요 |

---

## Part 3. AI 에이전트 시대의 차별점

### 3-1. 문서 소비자의 변화

**전환점**: Gartner 예측 — 2026년까지 API 수요의 30%+ 이 AI 에이전트에서 발생. 기계가 문서의 주요 소비자가 됨.

**대응 전략 2가지**:
- **분리 전략**: bkit처럼 `.pdca-status.json`(기계) + 보고서(사람) 명시 분리
- **통합 전략**: Markdown + YAML frontmatter로 "하나의 소스, 두 소비자"

**1인 개발자에게는 통합 전략이 현실적**. 별도의 기계용 문서를 유지하는 것은 부담.

**llms.txt 표준**: Jeremy Howard 제안(2024). 프로젝트 루트에 LLM이 즉시 이해할 수 있는 구조화된 진입점 제공.

### 3-2. Context Engineering과 문서 설계

**정의**: "LLM 추론 시 최적의 토큰 집합을 큐레이션하고 유지하는 전략의 집합" (Anthropic)

**핵심 개념**:
- Karpathy: "context window = RAM" — 모델의 작업 메모리
- Willison: "Context engineering은 fine-tuning 대신 우리가 하는 것"
- **Context Rot**: 200K 토큰 모델에서 오히려 성능 불안정 심화. 더 많은 토큰 ≠ 더 나은 성능

**토큰 예산 배분 프레임워크**:

| 영역 | 비율 | 설명 |
|------|------|------|
| System Instructions | 10-15% | 행동에 불균형적 영향 |
| History Context | 20-30% | 시간에 따라 증가, 능동 관리 필요 |
| Buffer Reserve | 10-15% | 없으면 치명적 실패 |

**시사점**: CLAUDE.md의 "모든 줄이 컨텍스트와 경쟁한다"는 기존 규칙이 Context Engineering 원칙과 정확히 일치. Just-In-Time Retrieval(Skills on-demand 로딩)도 이미 실천 중.

### 3-3. AI 지시 문서의 설계 원칙

**도구별 변형**:

| 파일 | 도구 | 관리 주체 |
|------|------|-----------|
| `CLAUDE.md` | Claude Code | Anthropic |
| `AGENTS.md` | 범용 (OpenAI Codex, Jules, Cursor 등) | Linux Foundation |
| `.cursorrules` | Cursor | Cursor |
| `.github/copilot-instructions.md` | GitHub Copilot | GitHub |

**공통 설계 원칙**:
1. WHY-WHAT-HOW 구조
2. 간결함이 핵심 (300줄 미만, 이상적으로 60줄 미만)
3. 포인터 > 복사본 (코드 스니펫 인라인 대신 `file:line` 참조)
4. 린터에게 맡길 것은 린터에게
5. 내구성 있는 규칙(CLAUDE.md) vs. 일시적 목표(프롬프트)

**현재 환경 평가**: CLAUDE.md 구조(간결 + Skills 분리 + handoff + Git 기반)는 업계 모범 사례와 일치.

### 3-4. 자동 생성 문서의 신뢰성과 검증 루프

**Hallucination 현황 (2025)**: 의료 1.47%, 모바일 앱 리뷰 1.75%. 법적 영향 확대 — 2025년 관련 판결의 90%가 해당 연도에 집중.

**검증 전략 스펙트럼**:

| 수준 | 방식 | 사례 |
|------|------|------|
| 자동-경량 | 린트, 링크 체크, 포맷 검증 | Docs-as-Code CI |
| 자동-중량 | Match Rate, 계획 vs 실행 갭 탐지 | bkit gap-detector |
| 반자동 | RLHF식 피드백 루프 | 조아영 /morning→/wrap→/evening |
| 수동 | Human-in-the-Loop 에스컬레이션 | 의심 건만 사람 검토 |

**시사점**: "신뢰하되 검증하라" — AI 생성 문서는 최소한 diff 리뷰 수행. `/wrap` 세션 마무리에 검증 단계 내장.

### 3-5. AI 에이전트 시대 문서 관리 6대 원칙

| # | 원칙 | 핵심 질문 | 1인 개발자 실천 |
|---|------|-----------|----------------|
| 1 | **이중 청중 설계** | 기계도 파싱할 수 있는가? | Markdown + YAML frontmatter |
| 2 | **토큰 예산 인식** | context window를 얼마나 차지하는가? | CLAUDE.md 60줄 이내, Skills 분리 |
| 3 | **Progressive Disclosure** | 상시 로드 vs 필요 시 로드가 분리되었는가? | CLAUDE.md(상시) + Skills(on-demand) |
| 4 | **순환적 자기 검증** | AI 생성 내용을 어떻게 검증하는가? | /wrap 검증 + gap-detector 패턴 |
| 5 | **문서는 인프라** | 코드처럼 테스트/버전 관리되는가? | Git + docs-as-code + pre-commit |
| 6 | **구조화된 메타데이터** | 기계가 구조적으로 파악할 수 있는가? | frontmatter + JSON 상태 파일 |

---

## Part 4. 종합

### 4-1. 비개발/개발 공통 패턴

3개 Part를 관통하는 공통 패턴 5가지:

| # | 패턴 | 비개발 | 개발 | AI 에이전트 시대 |
|---|------|--------|------|-----------------|
| 1 | **의사결정 기록** | Decision Log, Decision Journal | ADR, MADR | AI에게 "왜"를 설명하는 문서 |
| 2 | **SSOT** | 중앙 액션 트래커 | OpenAPI spec, plugin.json | CLAUDE.md = 프로젝트 규칙의 SSOT |
| 3 | **피드백 루프** | 포스트모템, 회고 | CI/CD 검증 | RLHF식 자기개선 루프 |
| 4 | **최소 충분 문서** | Agile JBGE | Docs-as-Code | 토큰 예산 인식 설계 |
| 5 | **문서 부패 방지** | 정기 리뷰, 삭제 정책 | 코드 옆 배치, 자동 신선도 체크 | Hook 기반 자동 갱신 |

### 4-2. 가설 검증 결과

| # | 가설 | 판정 | 근거 |
|---|------|------|------|
| 1 | 전통 PM 문서의 80%는 읽히지 않음 → AI 시대 자동 소비가 해법 | **확인** | PMBOK 7판의 원칙 전환, Gartner API 수요 30%+ AI 에이전트 예측, JBGE 원칙의 확산 |
| 2 | 사람용/AI용 문서는 형식이 달라야 한다 | **수정** | 분리보다 **"하나의 소스, 두 소비자"**(Markdown + YAML frontmatter) 전략이 1인 환경에 현실적. 대규모 프로젝트에서는 분리(bkit식)도 유효 |
| 3 | 비개발 영역의 가장 큰 공백은 의사결정 기록 부재 | **확인** | ADR은 개발에 정착. 비개발에서 동일 형식(Decision Record)의 채택이 부족하나, MADR 형식으로 즉시 확장 가능 |
| 4 | Context Engineering은 PARA/Zettelkasten의 AI 시대 재발견 | **수정** | 재발견이 아니라 **보완적 관계**. PARA = 정보 분류 체계, Context Engineering = 런타임 토큰 큐레이션 전략. 목적이 다름. 단, "필요한 정보를 적시에 제공"이라는 철학은 공유 |

### 4-3. 개인 실행 로드맵

#### 즉시 적용 (이번 주)

| # | 항목 | 구현 방법 | 난이도 |
|---|------|-----------|--------|
| 1 | **Decision Record 도입** | `decisions/` 폴더에 MADR minimal 템플릿. 첫 번째: "왜 hooks.json에 이중 배열 구조를 사용하는가" | 낮음 |
| 2 | **YAML frontmatter 일관 적용** | Obsidian Templater로 신규 노트 자동 frontmatter 삽입 (`type`, `date`, `status`, `tags`) | 낮음 |
| 3 | **CLAUDE.md 역할 명시** | 현재 CLAUDE.md에 "이 파일의 역할: 규칙 + 아키텍처 요약. 왜(Why)는 decisions/ 참조" 한 줄 추가 | 낮음 |

#### 중기 (1-2주)

| # | 항목 | 구현 방법 | 난이도 |
|---|------|-----------|--------|
| 4 | **`/wrap` 검증 단계 추가** | wrap 스킬에 "계획 vs 실행 gap 체크" 프롬프트 추가. bkit의 gap-detector 경량 버전 | 중간 |
| 5 | **SessionStart handoff 자동 참조** | SessionStart hook에서 최신 handoff 파일 경로를 출력 → 사용자에게 안내 | 중간 |
| 6 | **플러그인별 트러블슈팅 가이드** | 각 플러그인 디렉토리에 `TROUBLESHOOT.md` (Runbook 경량 버전) | 낮음 |

#### 하지 않아도 될 것

| 항목 | 이유 |
|------|------|
| SSG (MkDocs/Docusaurus) 도입 | 현재 규모에서 GitHub Markdown 렌더링으로 충분 |
| Wiki 플랫폼 (Notion/Confluence) | 1인 개발, Git 리포가 Wiki |
| API 문서화 도구 (Scalar/Redoc) | REST API 없음 |
| 복잡한 ADR 도구 (Log4brains) | Markdown 파일로 충분 |
| bkit급 PDCA 시스템 전체 도입 | 복잡도 대비 효과 불확실. 필요한 패턴만 차용 |

### 4-4. 현재 환경 평가 — 이미 잘 하고 있는 것

| 실천 항목 | 해당 개념 |
|-----------|-----------|
| CLAUDE.md (전역 + 프로젝트별) | AI 지시 문서, Context Engineering |
| Skills on-demand 로딩 | Progressive Disclosure, 토큰 예산 |
| CHANGELOG.md 커밋마다 기록 | 변경 로그 SSOT, Docs-as-Code |
| handoff/ 문서 | 세션 간 연속성 |
| plugin.json ↔ marketplace.json 일치 검증 | SSOT + 자동 검증 |
| 서브에이전트 위임 (리서치/탐색) | Sub-Agent Architecture |
| auto memory | 장기 기억 (Long-term memory) |
| vault-ops 스킬 (위키링크 보호) | Zettelkasten 링크 무결성 |

---

## 출처 종합

### Part 1 — 비개발 영역
- [PMBOK 7 vs PMBOK 8](https://projectmanagementacademy.net/resources/blog/pmbok-7-vs-pmbok-8-differences/)
- [PRINCE2 Documents Guide](https://www.knowledgehut.com/blog/project-management/prince2-documents)
- [Agile "Just Enough" Documentation](https://www.testrail.com/blog/lean-documentation-agile-project/)
- [PARA Method - Forte Labs](https://fortelabs.com/blog/para/)
- [Zettelkasten - Zenkit](https://zenkit.com/en/blog/a-beginners-guide-to-the-zettelkasten-method/)
- [Agentic Knowledge Management](https://www.dsebastien.net/agentic-knowledge-management-the-next-evolution-of-pkm/)
- [Decision Log - Monday.com](https://monday.com/blog/project-management/decision-log/)
- [Decision Journal - fs.blog](https://fs.blog/decision-journal/)
- [Fellow.ai - Meeting Action Items](https://fellow.ai/blog/how-to-manage-meeting-tasks-and-action-items/)
- [Obsidian PKM - Glukhov](https://www.glukhov.org/post/2025/07/obsidian-for-personal-knowledge-management/)

### Part 2 — 개발 영역
- [ADR GitHub](https://adr.github.io/) / [MADR](https://adr.github.io/madr/)
- [AWS - ADR Best Practices](https://aws.amazon.com/blogs/architecture/master-architecture-decision-records-adrs-best-practices-for-effective-decision-making/)
- [Pinterest - Docs-as-Code](https://medium.com/pinterest-engineering/adopting-docs-as-code-at-pinterest-4f18ad169c25)
- [Squarespace - Docs-as-Code Journey](https://engineering.squarespace.com/blog/2025/making-documentation-simpler-and-practical-our-docs-as-code-journey)
- [APIs You Won't Hate - Top 5 API Docs Tools 2025](https://apisyouwonthate.com/blog/top-5-best-api-docs-tools/)
- [DEV - Why Your Engineering Wiki is a Graveyard](https://dev.to/kislay/why-your-engineering-wiki-is-a-graveyard-and-how-to-fix-it-2eme)
- [IncidentHub - Runbook Best Practices](https://blog.incidenthub.cloud/The-No-Nonsense-Guide-to-Runbook-Best-Practices)
- [Addy Osmani - Beyond Vibe Coding](https://beyond.addy.ie/)

### Part 3 — AI 에이전트 시대
- [Anthropic - Context Engineering](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)
- [Simon Willison - Context Engineering](https://simonwillison.net/2025/jun/27/context-engineering/)
- [LangChain - Context Engineering for Agents](https://blog.langchain.com/context-engineering-for-agents/)
- [llms.txt Specification](https://llmstxt.org/)
- [Mintlify - Documentation for AI+Human](https://www.mintlify.com/blog/structure-documentation-AI-human-readers)
- [AGENTS.md Specification](https://agents.md/)
- [HumanLayer - Writing a Good CLAUDE.md](https://www.humanlayer.dev/blog/writing-a-good-claude-md)
- [AI Hallucination Testing Guide](https://testfort.com/blog/ai-hallucination-testing-guide)
- [Anthropic 2026 Agentic Coding Trends](https://resources.anthropic.com/2026-agentic-coding-trends-report)

### 기존 분석 자료
- `bkit_문서화시스템_분석_20260225.md` — bkit PDCA 시스템 상세 분석
- `문서관리_비교분석_20260225.md` — 5개 사례 비교 매트릭스
- `문서관리_사례들.md` — team-attention, 조아영, 마누스, 류장근, B.L.A.S.T. 상세
