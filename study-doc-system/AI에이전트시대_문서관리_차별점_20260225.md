# AI 에이전트 시대의 문서 관리 차별점

> 조사일: 2026-02-25
> 목적: AI 에이전트가 문서를 "소비"하는 시대에 문서 관리가 어떻게 달라져야 하는지 분석
> 컨텍스트: bkit, team-attention, 조아영, 마누스, 류장근 5개 사례 분석을 기반으로 일반화

---

## 3-1. 문서 소비자의 변화 — 사람용 vs. 기계용 문서 분리

### 핵심 내용

- **Gartner 예측**: 2026년까지 API 수요의 30% 이상이 사람이 아닌 AI 에이전트에서 발생할 것. 기계가 사람을 추월하여 문서의 주요 소비자가 되는 전환점
- **문서의 이중 목적**: 전통적 문서는 "사람이 이해하도록" 작성되었으나, AI 시대 문서는 "기계가 해석하고, 추론하고, 행동할 수 있도록" 구조화해야 함
- **Dual-format 전략 부상**: 하나의 문서가 사람과 기계를 동시에 만족시키거나, 명시적으로 분리하는 두 가지 접근법이 공존
- **llms.txt 표준 제안**: Jeremy Howard(Answer.AI 공동 창업자)가 2024년 9월 제안. robots.txt 에서 영감을 받아, 웹사이트가 LLM에게 핵심 정보를 제공하는 표준 형식
  - `/llms.txt`: 문서 구조 네비게이션 (간결 버전)
  - `/llms-full.txt`: 전체 문서 통합본
  - 형식은 Markdown (LLM이 학습 데이터로 가장 많이 접한 형식)
- **Cloudflare "Markdown for Agents"**: HTML 페이지를 AI 에이전트가 요청 시 자동으로 Markdown으로 변환하여 제공 (HTTP content negotiation 활용)
- **Machine-first documentation**: "문서를 인프라처럼 생각하라 — 구조화되고, 테스트 가능하고, 검색 가능하게 설계"

### 구체적 사례/도구

| 도구/형식 | 용도 | 특징 |
|-----------|------|------|
| `llms.txt` / `llms-full.txt` | 웹사이트→LLM 정보 제공 | Markdown 기반, 5개 섹션 구조 |
| Cloudflare Markdown for Agents | HTML→Markdown 자동 변환 | `Accept: text/markdown` 헤더로 트리거 |
| YAML frontmatter | 문서 메타데이터 | 사람에게는 보이지 않으나 기계가 파싱 |
| Gitingest | 레포→LLM 요약 | 복잡한 코드베이스를 소화 가능한 형태로 |
| Mintlify MAGI | AI 가이드용 Markdown | YAML frontmatter 필드로 에이전트 안내 |
| bkit `.pdca-status.json` | 프로젝트 상태 기계용 | JSON 구조, 에이전트가 직접 파싱 |

### 출처

- [The Future of Documentation: From Human-Readable to LLM-Friendly](https://blog.zylosystems.com/posts/documentation-for-llms)
- [The /llms.txt file specification](https://llmstxt.org/)
- [How to structure documentation for both AI and human readers](https://www.mintlify.com/blog/structure-documentation-AI-human-readers)
- [The Future of Documentation Is Machine-First](https://www.catchyagency.com/post/the-future-of-documentation-is-machine-first)
- [Major AI Documentation Trends for 2026](https://document360.com/blog/ai-documentation-trends/)

### 1인 개발자(Obsidian + Claude Code)에 대한 시사점

- **즉시 적용 가능**: Obsidian 노트에 YAML frontmatter를 일관되게 추가하면, 같은 파일이 사람(Obsidian UI)과 기계(Claude Code 에이전트) 모두에게 유용
- **분리보다 통합이 현실적**: 1인 개발자에게 별도의 기계용 문서를 유지하는 것은 부담. 대신 Markdown + YAML frontmatter로 "하나의 소스, 두 가지 소비자" 전략 추천
- **bkit 패턴 참조**: `.pdca-status.json`(기계용) + `plan/design/report`(사람용) 분리는 프로젝트 관리에서 유효. 에이전트가 자동으로 JSON 상태를 읽고 사람은 보고서만 확인
- **llms.txt는 개인 프로젝트에도 유용**: 프로젝트 루트에 `llms.txt`를 두면 AI 도구들이 프로젝트를 빠르게 이해

---

## 3-2. Context Engineering과 문서 설계

### 핵심 내용

- **Context Engineering 정의**: "LLM 추론 시 최적의 토큰 집합을 큐레이션하고 유지하는 전략의 집합" (Anthropic). Prompt Engineering의 자연스러운 진화
- **Andrej Karpathy의 비유**: "LLM은 새로운 종류의 운영체제. LLM이 CPU라면 context window는 RAM — 모델의 작업 메모리." Context engineering은 "다음 단계를 위해 context window에 딱 맞는 정보를 채우는 예술이자 과학"
- **Simon Willison**: "Context engineering은 fine-tuning 대신 우리가 하는 것." "추론된 정의가 결국 고착된다" — prompt engineering보다 실제 전문 실무를 더 잘 전달하는 용어
- **Tobi Lutke(Shopify CEO)**: "LLM이 과제를 그럴듯하게 풀 수 있도록 모든 컨텍스트를 제공하는 예술"
- **Context Rot 현상**: Chroma 연구(Hong et al., 2025)에서 18개 LLM 측정 — "모델은 컨텍스트를 균일하게 사용하지 않으며, 입력 길이가 길어질수록 성능이 점점 더 불안정해진다." 200K 토큰 모델에서 오히려 context rot이 더 심각
- **4대 핵심 전략** (Anthropic 공식):
  1. **System Prompt Calibration**: XML 태그나 Markdown 헤더로 구분된 섹션, 구체적 신호 제공
  2. **Tool Design Efficiency**: 자기 완결적, 최소 기능 중복
  3. **Example Curation**: 다양하고 표준적인 few-shot 예제
  4. **Just-In-Time Retrieval**: 사전 로딩 대신 경량 식별자(파일 경로, 링크)로 런타임 동적 로딩
- **토큰 예산 배분 프레임워크**:
  - System Instructions: 10-15% (행동에 불균형적 영향)
  - History Context: 20-30% (시간에 따라 증가, 능동 관리 필요)
  - Buffer Reserve: 10-15% (예비 용량 없으면 치명적 실패)
- **장기 작업 해법**:
  - **Compaction**: 대화 히스토리 요약으로 context window 리셋
  - **Structured Note-Taking**: 외부 메모리 파일로 다시간 일관성 유지
  - **Sub-Agent Architecture**: 전문 에이전트가 집중 작업 후 1,000-2,000 토큰 요약 반환

### 구체적 사례/도구

| 개념/도구 | 설명 |
|-----------|------|
| Anthropic MCP | AI 시스템을 도구/DB/외부 컨텍스트에 연결하는 표준 프로토콜 |
| Factory Repository Overview | 레포마다 구조/패키지/빌드 명령/핵심 파일 요약 자동 생성 |
| Context Window 동적 할당 | 쿼리/상태에 따라 시스템/히스토리/검색 비율 실시간 조정 |
| 마누스 3-파일 패턴 | `task_plan.md` + `findings.md` + `progress.md` = 외부 메모리 |
| bkit 16에이전트 | 에이전트별 전용 컨텍스트 격리, 요약만 오케스트레이터에 반환 |

### 출처

- [Effective context engineering for AI agents (Anthropic 공식)](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)
- [Context engineering (Simon Willison)](https://simonwillison.net/2025/jun/27/context-engineering/)
- [Context Engineering for Agents (LangChain)](https://blog.langchain.com/context-engineering-for-agents/)
- [The Context Window Problem (Factory.ai)](https://factory.ai/news/context-window-problem)
- [The Hidden Costs of Context Windows (BrimLabs)](https://brimlabs.ai/blog/the-hidden-costs-of-context-windows-optimizing-token-budgets-for-scalable-ai-products/)
- [2025 LLM Year in Review (Karpathy)](https://karpathy.bearblog.dev/year-in-review-2025/)

### 1인 개발자(Obsidian + Claude Code)에 대한 시사점

- **CLAUDE.md는 토큰 예산의 일부**: 매 세션 자동 로드되므로 간결해야 한다. "모든 줄이 컨텍스트와 경쟁한다"는 기존 규칙이 Context Engineering 원칙과 정확히 일치
- **Just-In-Time Retrieval 적용**: CLAUDE.md에는 포인터(파일 경로, 간단한 설명)만 두고, 실제 상세 지침은 Skills/별도 파일로 분리 → on-demand 로딩. 이미 실행 중인 패턴
- **외부 메모리 파일 패턴 활용**: handoff 문서, `.pdca-status.json` 등은 context window를 넘어서는 장기 기억 역할. 마누스의 3-파일 패턴처럼 `task_plan` + `findings` + `progress` 구조 채택 가능
- **Sub-Agent 위임**: "탐색/리서치/코드 분석은 서브에이전트에 위임해 메인 컨텍스트를 보호하라"는 기존 규칙이 Anthropic의 Sub-Agent Architecture 권장 사항과 동일

---

## 3-3. CLAUDE.md / AGENTS.md 등 AI 지시 문서의 설계 원칙

### 핵심 내용

- **CLAUDE.md**: Claude Code가 매 세션 시작 시 읽는 Markdown 파일. 코딩 표준, 아키텍처 결정, 선호 라이브러리, 리뷰 체크리스트 설정
- **AGENTS.md**: Google, OpenAI, Factory, Sourcegraph, Cursor가 공동 발표한 오픈 표준. "에이전트를 위한 README". Linux Foundation 산하 Agentic AI Foundation이 관리
  - 20개 이상의 AI 코딩 에이전트가 인식 (OpenAI Codex, Google Jules, Cursor, GitHub Copilot, Devin 등)
  - 표준 Markdown, 필수 필드 없음, 도구 불가지론적(tool-agnostic)
  - 모노레포에서 디렉토리별 중첩 가능
- **도구별 AI 지시 파일 변형**:

| 파일 | 도구 | 비고 |
|------|------|------|
| `CLAUDE.md` | Claude Code | 전역(`~/.claude/`) + 프로젝트별 |
| `AGENTS.md` | OpenAI Codex, Jules, Cursor 등 | 오픈 표준, Linux Foundation |
| `.cursorrules` | Cursor | 프로젝트별 규칙 |
| `.github/copilot-instructions.md` | GitHub Copilot | GitHub 네이티브 |
| `.windsurfrules` | Windsurf | Cursor 유사 |
| `.clinerules` | Cline | VSCode 확장 |

- **공통 설계 원칙**:
  1. **WHY-WHAT-HOW 구조**: 프로젝트 목적(WHY), 기술 스택/구조(WHAT), 개발 워크플로(HOW)
  2. **간결함이 핵심**: Frontier LLM은 ~150-200개 지시를 합리적으로 따름. Claude Code 시스템 프롬프트가 이미 ~50개 → CLAUDE.md는 최소한으로
  3. **포인터 > 복사본**: 코드 스니펫 인라인 대신 `file:line` 참조. 복사본은 금방 구식화
  4. **린터에게 맡길 것은 린터에게**: "LLM에게 린터 일을 시키지 마라." 코드 스타일은 도구로 강제
  5. **내구성 있는 규칙 vs. 일시적 목표**: CLAUDE.md에는 장기 규범, 프롬프트에는 단기 과제
  6. **300줄 미만, 이상적으로 60줄 미만**: 짧을수록 지시 준수율 향상
- **Trail of Bits의 접근**: opinionated defaults + 문서 + 워크플로 분리

### 구체적 사례/도구

- [Writing a good CLAUDE.md (HumanLayer)](https://www.humanlayer.dev/blog/writing-a-good-claude-md)
- [AGENTS.md specification](https://agents.md/)
- [AGENTS.md – One File to Guide Them All (Layer5)](https://layer5.io/blog/ai/agentsmd-one-file-to-guide-them-all/)
- [Trail of Bits claude-code-config](https://github.com/trailofbits/claude-code-config)
- [awesome-claude-code](https://github.com/hesreallyhim/awesome-claude-code)
- [Custom instructions with AGENTS.md (OpenAI)](https://developers.openai.com/codex/guides/agents-md/)
- [The Ultimate CLAUDE.md Configuration (Deeplearning.fr)](https://deeplearning.fr/the-ultimate-claude-md-configuration-transform-your-ai-development-workflow/)

### 1인 개발자(Obsidian + Claude Code)에 대한 시사점

- **현재 CLAUDE.md 구조는 모범 사례에 부합**: 전역 + 프로젝트별 분리, Skills로 on-demand 이동, 간결 유지 원칙 모두 업계 권장 사항과 일치
- **AGENTS.md 호환 고려**: 프로젝트를 오픈소스로 공개하거나 다른 AI 도구를 사용할 계획이 있다면 AGENTS.md도 추가 검토. 단, 현재 Claude Code 전용이라면 CLAUDE.md만으로 충분
- **Progressive Disclosure 패턴**: `building_the_project.md`, `running_tests.md` 등 태스크별 문서 분리 후 CLAUDE.md에서 한 줄 설명으로 참조 → Skills 패턴과 동일

---

## 3-4. 자동 생성 문서의 신뢰성과 검증 루프

### 핵심 내용

- **Hallucination 현황** (2025):
  - 의료 문서: 1.47% hallucination rate, 3.45% omission rate
  - 모바일 앱 리뷰: 약 1.75% hallucination 빈도
  - 법적 영향: 2025년에만 전 세계 법원에서 수백 건의 AI hallucination 관련 판결. 전체 알려진 사례의 약 90%가 2025년에 집중
- **근본 원인**: 2025년 연구는 hallucination을 "시스템적 인센티브 문제"로 재정의 — 학습 목표와 벤치마크가 보정된 불확실성보다 자신감 있는 추측을 보상
- **핵심 검증 전략**:
  1. **RAG(Retrieval-Augmented Generation)**: 외부 지식 기반에서 관련 정보 검색 후 모델에 제공. 단, "문서를 잘못 읽거나, 과도하게 일반화하거나, 주장을 날조" 가능
  2. **Span-level Verification**: 생성된 각 주장(claim)을 검색된 증거와 대조, 근거 없으면 플래그 (REFIND SemEval 2025 벤치마크)
  3. **AWS Automated Reasoning Checks**: 수학적 증명 기반 검증으로 최대 99% 검증 정확도. 형식 검증(formal verification) 접근
  4. **Multi-Judge Consensus**: 2-3명의 리뷰어가 각 샘플을 검토, 불일치 시 추가 감사 라운드
  5. **Human-in-the-Loop (HITL)**: "더 이상 틈새 안전장치가 아니라, 신뢰를 운영화하는 기본 전략"
- **자동+수동 하이브리드**: 대부분 콘텐츠는 자동 검사, 의심스러운 경우만 사람에게 에스컬레이션
- **Gold Standard 검증**: 도메인 전문가가 사전 승인한 "골드 스탠다드" 세트에 대해 어노테이터 간 동의율(inter-annotator agreement) 70% 이상 요구

### 구체적 사례/도구

| 검증 방식 | 도구/사례 | 특징 |
|-----------|----------|------|
| 자동 매칭률 | bkit gap-detector (Match Rate) | 계획 vs 실행 자동 비교 |
| 중복 검사 | team-attention duplicate-checker | 세션 분석에서 중복 패턴 탐지 |
| Span-level 검증 | REFIND (SemEval 2025) | 주장별 증거 매칭 |
| 형식 검증 | AWS Automated Reasoning | 수학적 증명 기반, 99% 정확도 |
| RLHF식 피드백 | 조아영 자기개선 루프 | 사용자 피드백으로 에이전트 행동 교정 |
| Self-healing docs | Docs-as-code 파이프라인 | 자동 검증 + 자동 수정 |

### 출처

- [AI Hallucination Testing Guide (TestFort)](https://testfort.com/blog/ai-hallucination-testing-guide)
- [Hallucination Rates in 2025 (Medium)](https://medium.com/@markus_brinsa/hallucination-rates-in-2025-accuracy-refusal-and-liability-aa0032019ca1)
- [Stop AI Hallucinations: Detection, Prevention & Verification Guide 2025](https://infomineo.com/artificial-intelligence/stop-ai-hallucinations-detection-prevention-verification-guide-2025/)
- [AWS Automated Reasoning Checks](https://aws.amazon.com/blogs/aws/minimize-ai-hallucinations-and-deliver-up-to-99-verification-accuracy-with-automated-reasoning-checks-now-available/)
- [HITL in AI Documentation (Google Cloud)](https://docs.google.com/document-ai/docs/hitl)
- [The Role of HITL in AI-Driven Data Management (TDWI)](https://tdwi.org/articles/2025/09/03/adv-all-role-of-human-in-the-loop-in-ai-data-management.aspx)

### 1인 개발자(Obsidian + Claude Code)에 대한 시사점

- **"신뢰하되 검증하라" 원칙**: AI가 생성한 문서를 그대로 커밋하지 말고, 최소한 diff 리뷰 수행. `/wrap` 같은 세션 마무리 워크플로에 검증 단계 내장
- **Match Rate 패턴 채택 가능**: 계획 문서와 실행 결과를 자동 비교하는 간단한 스크립트. bkit의 gap-detector처럼 "계획에 있었으나 실행하지 않은 것" 자동 탐지
- **조아영의 RLHF식 루프**: `/morning` → `/wrap` → `/evening` 순환에서 "오늘 Claude가 잘못 생성한 것" 피드백 기록 → 다음 세션에서 개선. 1인 개발자도 daily 루프로 품질 향상 가능
- **자동 lint/format + 수동 내용 검토 분리**: 형식은 도구가 검증, 내용은 사람이 검증하는 하이브리드 모델

---

## 3-5. AI 에이전트 시대 문서 관리 원칙 도출

### 핵심 내용

- **Anthropic 2026 Agentic Coding Trends Report**:
  - 개발자가 AI를 작업의 60%에 통합하면서도 위임된 작업의 80-100%에 대해 능동적 감독 유지
  - "Repository Intelligence" — 코드 줄뿐 아니라 관계와 의도를 이해하는 AI
  - 데이터 최소화: "프롬프트, 코드 컨텍스트, 도구 출력을 기본적으로 민감하게 취급, 필요한 파일과 발췌문만 검색"
- **파일 기반 메모리 시스템의 수렴 진화**:
  - Manus, OpenClaw(145K+ stars), Claude Code가 독립적으로 같은 패턴 선택
  - Meta가 Manus를 $2B에 인수 — 경쟁 우위가 "평문 파일과 파일 기반 계획으로 메모리를 관리하는 방식"
  - "업계가 가정한 것보다 올바른 추상화가 더 단순할 수 있다"
- **Markdown 기반 메모리의 5가지 장점**:
  1. **투명성**: 텍스트 에디터로 에이전트의 메모리를 직접 읽을 수 있음
  2. **버전 관리**: Git 레포에 코드와 함께 관리
  3. **이식성**: 벤더 종속 없음, 모델 교체 시 같은 파일 제공
  4. **비용 효율**: 로컬 스토리지 $0.02/GB/월 vs. 벡터 DB $50-200/GB/월
  5. **즉시 검색 가능**: grep으로 충분 (1,000 파일 미만)
- **4가지 메모리 유형**:

| 유형 | 지속 시간 | 목적 | 문서 대응 |
|------|-----------|------|-----------|
| Short-term | 분 단위 | 현재 대화 컨텍스트 | context window |
| Long-term | 무기한 | 사실, 선호, 결정 | MEMORY.md, CLAUDE.md |
| Procedural | 영구 | 학습된 워크플로/스킬 | Skills, commands |
| Working | 초-분 단위 | 사고 과정 | scratchpad, task_plan |

### 5개 사례에서 도출한 공통 원칙

기존 분석한 5개 사례와 이번 리서치를 종합하여 다음 원칙을 도출:

#### 원칙 1: 이중 청중 설계 (Dual-Audience Design)

> 모든 문서는 사람과 기계 두 소비자를 고려하여 설계한다.

- **bkit**: `.pdca-status.json`(기계) + `plan/design/report`(사람) 명시적 분리
- **team-attention**: `CLAUDE.md`(기계 지시) + `context.md`(사람+기계 공유 컨텍스트)
- **업계 합의**: Markdown + YAML frontmatter = 사람이 읽을 수 있으면서 기계가 파싱 가능한 최적 형식

#### 원칙 2: 토큰 예산 인식 설계 (Token-Budget-Aware Design)

> 문서의 모든 줄은 context window의 토큰 예산과 경쟁한다. 간결함은 미덕이 아니라 필수.

- **Anthropic**: "다음 단계에서 원하는 결과의 가능성을 최대화하는 최소한의 고신호 토큰 집합을 찾아라"
- **CLAUDE.md 권장**: 300줄 미만, 이상적으로 60줄 미만
- **마누스**: 3파일만으로 충분한 외부 메모리 — 최소주의적 설계
- **Context Rot**: 더 많은 토큰 ≠ 더 나은 성능. 오히려 성능 저하

#### 원칙 3: Progressive Disclosure (점진적 노출)

> 핵심 정보만 항상 로드하고, 상세 정보는 필요할 때 동적으로 로드한다.

- **bkit**: 16에이전트 각각 전용 컨텍스트, 오케스트레이터에는 요약만
- **team-attention**: `context.md` 자동 업데이트로 최신 상태만 유지
- **Claude Code Skills**: CLAUDE.md에서 분리하여 on-demand 로딩
- **Factory**: 레포 요약(항상 로드) → 의미 검색(필요 시) → 특정 라인 범위(정밀 작업 시)

#### 원칙 4: 순환적 자기 검증 (Cyclical Self-Verification)

> AI 생성 문서는 자동화된 검증 루프를 통해 신뢰성을 확보한다.

- **bkit**: gap-detector로 계획 vs 실행 Match Rate 자동 측정
- **조아영**: `/morning`→`/wrap`→`/evening` 일일 순환, RLHF식 피드백
- **team-attention**: duplicate-checker로 중복 패턴 자동 탐지
- **업계**: Span-level verification, Multi-Judge Consensus, HITL 에스컬레이션

#### 원칙 5: 문서는 인프라다 (Documentation as Infrastructure)

> 문서를 부산물이 아닌 시스템의 핵심 인프라로 취급한다. 코드처럼 테스트하고, 버전 관리하고, 배포한다.

- **류장근**: md 칸반 + Scalar API 문서 + 커밋-칸반 연동 = 문서가 프로젝트 상태의 단일 진실 소스
- **마누스**: "결정 전 재참조" 규칙 = 문서가 행동을 통제
- **Docs-as-code**: 구조화, 테스트 가능, 자기 수복(self-healing) 문서 파이프라인
- **Git 기반 메모리**: 코드와 문서가 같은 레포에서 같은 버전 관리 체계로 관리

#### 원칙 6: 구조화된 메타데이터 우선 (Structured Metadata First)

> 기계가 파싱할 수 있는 구조화된 메타데이터를 모든 문서에 포함한다.

- **형식**: YAML frontmatter, JSON, Markdown with headers
- **bkit**: JSON 상태 파일로 에이전트 간 통신
- **team-attention**: CLAUDE.md frontmatter로 플러그인 소유권 판정
- **llms.txt**: 프로젝트 전체를 기계가 이해할 수 있는 구조화된 진입점

### 구체적 사례/도구

- [AI Agent Memory Management: When Markdown Files Are All You Need](https://dev.to/imaginex/ai-agent-memory-management-when-markdown-files-are-all-you-need-5ekk)
- [Structured AI Coding with Task Context (EclipseSource)](https://eclipsesource.com/blogs/2025/07/01/structure-ai-coding-with-task-context/)
- [2026 Agentic Coding Trends Report (Anthropic)](https://resources.anthropic.com/2026-agentic-coding-trends-report)
- [Anthropic: 8 agentic coding trends shaping software engineering in 2026](https://tessl.io/blog/8-trends-shaping-software-engineering-in-2026-according-to-anthropics-agentic-coding-report/)
- [Codified Context: Infrastructure for AI Agents in a Complex Codebase (arXiv)](https://arxiv.org/html/2602.20478)

### 1인 개발자(Obsidian + Claude Code)에 대한 시사점

- **이미 올바른 방향**: 현재 CLAUDE.md 구조(간결 + Skills 분리 + handoff 문서 + Git 기반)는 6개 원칙 대부분을 이미 실천 중
- **강화할 영역**:
  1. **YAML frontmatter 일관성**: 모든 Obsidian 노트와 프로젝트 문서에 일관된 frontmatter 스키마 적용
  2. **자동 검증 루프 추가**: `/wrap` 시 계획 vs 실행 gap을 자동 체크하는 간단한 hook
  3. **llms.txt 도입**: 프로젝트 루트에 프로젝트 개요를 LLM이 즉시 이해할 수 있는 형태로 제공
  4. **메모리 계층 명시화**: Short-term(context window) / Long-term(CLAUDE.md, MEMORY.md) / Procedural(Skills) / Working(handoff, task_plan) 구분을 의식적으로 운영

---

## 종합 요약: AI 에이전트 시대 문서 관리 6대 원칙

| # | 원칙 | 핵심 질문 | 1인 개발자 실천 |
|---|------|-----------|----------------|
| 1 | 이중 청중 설계 | 이 문서를 기계도 파싱할 수 있는가? | Markdown + YAML frontmatter |
| 2 | 토큰 예산 인식 | 이 문서가 context window를 얼마나 차지하는가? | CLAUDE.md 60줄 이내, Skills 분리 |
| 3 | Progressive Disclosure | 항상 로드할 것과 필요 시 로드할 것이 분리되었는가? | CLAUDE.md(상시) + Skills(on-demand) |
| 4 | 순환적 자기 검증 | AI 생성 내용을 어떻게 검증하는가? | daily 루프 + gap-detector 패턴 |
| 5 | 문서는 인프라 | 문서가 코드처럼 테스트/버전 관리되는가? | Git 기반 + docs-as-code |
| 6 | 구조화된 메타데이터 | 기계가 이 문서의 의미를 구조적으로 파악할 수 있는가? | frontmatter + JSON 상태 파일 |
